{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2aae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33acc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c53a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the indexes of non-anomalies for interpolation \n",
    "def interpolation_indexes(mylist, mynumber):\n",
    "    \n",
    "    left_neighbour = 0\n",
    "    right_neighbour = 0\n",
    "    \n",
    "    # check left neighbour\n",
    "    if((mynumber - 1) not in mylist):\n",
    "        left_neighbour = mynumber - 1\n",
    "    else:\n",
    "        min_number = mynumber\n",
    "        while min_number in mylist:\n",
    "            min_number = min_number - 1\n",
    "        left_neighbour = min_number\n",
    "    \n",
    "    # check right neighbour\n",
    "    if((mynumber + 1) not in mylist):\n",
    "        right_neighbour = mynumber + 1\n",
    "    else:\n",
    "        max_number = mynumber\n",
    "        while max_number in mylist:\n",
    "            max_number = max_number + 1\n",
    "        right_neighbour = max_number\n",
    "    \n",
    "    return left_neighbour, right_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27daa684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    L1 = LSTM(16, activation='relu', return_sequences=True, \n",
    "            kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(8, activation='relu', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(X_train.shape[1])(L2)\n",
    "    L4 = LSTM(8, activation='relu', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n",
    "    output = TimeDistributed(Dense(X_train.shape[2]))(L5)    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804f0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anomaly_removal(df_train):\n",
    "    \n",
    "    # extract indexes for anomalies\n",
    "    indexes = list(df_train[df_train.is_anomaly == 1].index)\n",
    "\n",
    "    # creating a new df that replaces the anomalous samples with interpolation value\n",
    "    df = pd.DataFrame(columns = df_train.columns)\n",
    "    for i in range(0, len(df_train)):\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        # add all non-anomalies\n",
    "        if(df_train.is_anomaly[i] == 0):\n",
    "            df = df.append({'timestamp' : df_train.timestamp[i], 'value' : df_train.value[i], 'is_anomaly' : df_train.is_anomaly[i]},\n",
    "            ignore_index = True)\n",
    "\n",
    "        if((df_train.is_anomaly[i]==1) & (i != (len(df_train)-1)) & (i != 0)):\n",
    "            if(df_train.is_anomaly[i+1]!=1):\n",
    "                \n",
    "                if((interpolation_indexes(indexes, i)[0] != -1) & (interpolation_indexes(indexes, i)[1] != -1)):\n",
    "                    value_interpolation = (df_train.value[interpolation_indexes(indexes, i)[0]]\n",
    "                                           +df_train.value[interpolation_indexes(indexes, i)[1]])/2\n",
    "\n",
    "                    df = df.append({'timestamp' : df_train.timestamp[i], 'value': value_interpolation, 'is_anomaly' : 0.0}, ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf85af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_computing_max(X_train):\n",
    "    X_train_pred = model.predict(X_train, verbose=0)\n",
    "    train_mae_loss_avg = np.mean(np.abs(X_train_pred - X_train), axis=1)\n",
    "    max_threshold = np.max(train_mae_loss_avg)\n",
    "    return max_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3433298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss_predictions(X_test):\n",
    "    X_test_pred = model.predict(X_test, verbose=0)\n",
    "    mae_loss = np.mean(np.abs(X_test_pred-X_test), axis=1)\n",
    "    return mae_loss, X_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf729a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(mae_loss, threshold):\n",
    "    predicted_test_label = []\n",
    "    for i in range(0, len(test_mae_loss)):\n",
    "        if(test_mae_loss[i][0]>(threshold)):\n",
    "            predicted_test_label.append(1)\n",
    "        else:\n",
    "            predicted_test_label.append(0)\n",
    "    return predicted_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eebf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo\n",
    "#path_files = '../../../Documents/phd_related/data_sets_concept_drift/anomaly_detection/Yahoo_A1Benchmark/'\n",
    "# NAB\n",
    "path_files = '../../../Documents/phd_related/data_sets_concept_drift/anomaly_detection/NAB/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b714d4d",
   "metadata": {},
   "source": [
    "## Extract all file names corresponding to time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5156220",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_names = []\n",
    "for i in os.listdir(path_files):\n",
    "    ts_names.append(str(i.split('.csv')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb7b8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2_network_in_257a54\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 3s 33ms/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1/2 [00:22<00:22, 22.15s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2_network_in_257a54\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 3s 34ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1/2 [00:11<00:11, 11.99s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9b6995680aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# remove anomalies from train to prepare LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# all anomalies are replaced by the interpolation of their closest non-anomalous neighbours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_anomaly_removal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-236b1385b3a6>\u001b[0m in \u001b[0;36mtrain_anomaly_removal\u001b[0;34m(df_train)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# add all non-anomalies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_anomaly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             df = df.append({'timestamp' : df_train.timestamp[i], 'value' : df_train.value[i], 'is_anomaly' : df_train.is_anomaly[i]},\n\u001b[0m\u001b[1;32m     15\u001b[0m             ignore_index = True)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   9753\u001b[0m         )\n\u001b[1;32m   9754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9757\u001b[0m     def _append(\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   9777\u001b[0m             \u001b[0;31m# infer_objects is needed for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9778\u001b[0m             \u001b[0;31m#  test_append_empty_frame_to_series_with_dateutil_tz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9779\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9781\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36minfer_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6463\u001b[0m         \u001b[0;31m# native numpy numeric types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6464\u001b[0m         return self._constructor(\n\u001b[0;32m-> 6465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6466\u001b[0m         ).__finalize__(self, method=\"infer_objects\")\n\u001b[1;32m   6467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, copy, datetime, numeric, timedelta)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mtimedelta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     ) -> T:\n\u001b[0;32m--> 454\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0;34m\"convert\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# Split and operate column-by-column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_and_operate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msplit_and_operate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mres_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mrbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mres_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, copy, datetime, numeric, timedelta)\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m         res_values = soft_convert_objects(\n\u001b[0m\u001b[1;32m   2064\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m             \u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/concept_drift/venv/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36msoft_convert_objects\u001b[0;34m(values, datetime, numeric, timedelta, period, copy)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# bound of nanosecond-resolution 64-bit integers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             converted = lib.maybe_convert_objects(\n\u001b[0m\u001b[1;32m   1056\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 \u001b[0mconvert_datetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_final_results_details = pd.DataFrame(columns = ['TS_name', 'lstmae_reconstruction_loss'])\n",
    "df_final_results = pd.DataFrame(columns = ['TS_name', 'Labels_True', 'Labels_Pred', 'Test_Size', 'Model'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# for daily retraining NAB\n",
    "#window_retraining = 288\n",
    "\n",
    "# for weekly retraining NAB\n",
    "window_retraining = 2016\n",
    "\n",
    "# for weekly retraining Yahoo\n",
    "#window_retraining = 168\n",
    "\n",
    "for ts_name in tqdm(ts_names):\n",
    "    for n in range(0, 5):\n",
    "\n",
    "        label_pred_complete = []\n",
    "        losses_complete = []\n",
    "\n",
    "        print(ts_name)\n",
    "        # path to train/test\n",
    "        filename = path_files+ts_name+\".csv\"\n",
    "\n",
    "        # read ts\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "        # split into train and test\n",
    "        init_train = df[0:math.floor(len(df)/2)]\n",
    "        # print(len(init_train))\n",
    "        init_test = df[math.floor(len(df)/2):]\n",
    "        # print(len(init_test))\n",
    "\n",
    "\n",
    "        for i in tqdm(range(0, (math.floor(len(init_test)/window_retraining)+1))):\n",
    "\n",
    "            # adjust training over time\n",
    "            df_train = pd.concat([init_train, init_test[0:window_retraining*i]], ignore_index=True)\n",
    "\n",
    "\n",
    "            # adjust testing over time\n",
    "\n",
    "            if(i == (round(len(init_test)/window_retraining))):\n",
    "                df_test = init_test[(i)*window_retraining:]\n",
    "            else:\n",
    "                df_test = init_test[(i*window_retraining):((i+1)*window_retraining)]\n",
    "\n",
    "\n",
    "            # remove anomalies from train to prepare LSTM\n",
    "            # all anomalies are replaced by the interpolation of their closest non-anomalous neighbours\n",
    "            df_train = train_anomaly_removal(df_train)\n",
    "\n",
    "\n",
    "            # final training dataset + labels\n",
    "            label_train = df_train.is_anomaly\n",
    "            train = df_train.value\n",
    "\n",
    "\n",
    "\n",
    "            # final testing dataset + labels\n",
    "            label_test = df_test.is_anomaly\n",
    "            test = df_test.value\n",
    "            \n",
    "            # in case the training contains all data and there is no more data left for testing\n",
    "            if(df_test.empty):\n",
    "                break\n",
    "\n",
    "\n",
    "            # Data preprocessing - Scaling\n",
    "            # the scaler is fit on the training data and applied on the testing data\n",
    "            train_scale = scaler.fit_transform(np.array(train).reshape(-1, 1))\n",
    "            test_scale = scaler.transform(np.array(test).reshape(-1,1))\n",
    "\n",
    "            # Shape Train Data for LSTM\n",
    "            X_train = train_scale.reshape(train_scale.shape[0], 1, 1)\n",
    "\n",
    "            # Train LSTM\n",
    "            no_epochs = 50\n",
    "            batch_size = 128\n",
    "            model = lstm_model()\n",
    "            encdec = model.fit(X_train, X_train, epochs=no_epochs, batch_size=batch_size,\n",
    "                                validation_split=0.25).history\n",
    "\n",
    "            # Threshold computing\n",
    "            threshold = threshold_computing_max(X_train)\n",
    "\n",
    "            # Shape Test Data for LSTM\n",
    "            X_test = test_scale.reshape(test_scale.shape[0], 1, 1)\n",
    "\n",
    "            test_mae_loss, X_test_pred = reconstruction_loss_predictions(X_test)\n",
    "\n",
    "            # Extracting Predicted Labels\n",
    "            y_label_pred = predicted_labels(test_mae_loss, threshold)\n",
    "\n",
    "            label_pred_complete.append(y_label_pred)\n",
    "            losses_complete.append(threshold)\n",
    "\n",
    "        all_predicted_labels = []\n",
    "        for i in range(0, len(label_pred_complete)):\n",
    "            for j in range(0, len(label_pred_complete[i])):\n",
    "                all_predicted_labels.append(label_pred_complete[i][j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Save Results\n",
    "        # Save reconstruction Error for each Dataset\n",
    "        df_results_details = pd.DataFrame()\n",
    "        df_results_details['TS_name'] = [ts_name]\n",
    "        df_results_details['lstmae_reconstruction_loss'] = [losses_complete]\n",
    "        df_results_details['retraining_technique'] = 'full_history'\n",
    "        df_results_details['retraining_window'] = window_retraining\n",
    "        df_final_results_details = df_final_results_details.append(df_results_details)\n",
    "\n",
    "\n",
    "        # Save Predicted Labels\n",
    "        df_results = pd.DataFrame()\n",
    "\n",
    "\n",
    "        df_results['TS_name'] = [ts_name]\n",
    "        df_results['retraining_technique'] = 'full_history'\n",
    "        df_results['retraining_window'] = window_retraining\n",
    "        df_results['Labels_True'] = [list(init_test.is_anomaly)]\n",
    "        df_results['Labels_Pred'] = [all_predicted_labels]\n",
    "        df_results['Test_Size'] = len(list(init_test.is_anomaly))\n",
    "        df_results['Model'] = 'LSTM_AE'\n",
    "        df_final_results = df_final_results.append(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f801fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_results = df_final_results.reset_index(drop=True)\n",
    "df_final_results_details = df_final_results_details.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final_results.to_csv('./results/df_results_lstmae_periodic_fh.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
