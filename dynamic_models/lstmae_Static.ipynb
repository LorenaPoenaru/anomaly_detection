{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2aae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.layers import Input, Dense, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33acc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c53a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the indexes of non-anomalies for interpolation \n",
    "def interpolation_indexes(mylist, mynumber):\n",
    "    \n",
    "    left_neighbour = 0\n",
    "    right_neighbour = 0\n",
    "    \n",
    "    # check left neighbour\n",
    "    if((mynumber - 1) not in mylist):\n",
    "        left_neighbour = mynumber - 1\n",
    "    else:\n",
    "        min_number = mynumber\n",
    "        while min_number in mylist:\n",
    "            min_number = min_number - 1\n",
    "        left_neighbour = min_number\n",
    "    \n",
    "    # check right neighbour\n",
    "    if((mynumber + 1) not in mylist):\n",
    "        right_neighbour = mynumber + 1\n",
    "    else:\n",
    "        max_number = mynumber\n",
    "        while max_number in mylist:\n",
    "            max_number = max_number + 1\n",
    "        right_neighbour = max_number\n",
    "    \n",
    "    return left_neighbour, right_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87c8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    L1 = LSTM(16, activation='relu', return_sequences=True, \n",
    "            kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
    "    L2 = LSTM(8, activation='relu', return_sequences=False)(L1)\n",
    "    L3 = RepeatVector(X_train.shape[1])(L2)\n",
    "    L4 = LSTM(8, activation='relu', return_sequences=True)(L3)\n",
    "    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n",
    "    output = TimeDistributed(Dense(X_train.shape[2]))(L5)    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d78c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anomaly_removal(df_train):\n",
    "    \n",
    "    # extract indexes for anomalies\n",
    "    indexes = list(df_train[df_train.is_anomaly == 1].index)\n",
    "\n",
    "    # creating a new df that replaces the anomalous samples with interpolation value\n",
    "    df = pd.DataFrame(columns = df_train.columns)\n",
    "    for i in range(0, len(df_train)):\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        # add all non-anomalies\n",
    "        if(df_train.is_anomaly[i] == 0):\n",
    "            df = df.append({'timestamp' : df_train.timestamp[i], 'value' : df_train.value[i], 'is_anomaly' : df_train.is_anomaly[i]},\n",
    "            ignore_index = True)\n",
    "\n",
    "        if(df_train.is_anomaly[i]==1):\n",
    "            if(df_train.is_anomaly[i+1]!=1):\n",
    "                #print(i)\n",
    "                value_interpolation = (df_train.value[interpolation_indexes(indexes, i)[0]]+df_train.value[interpolation_indexes(indexes, i)[1]])/2\n",
    "\n",
    "                df = df.append({'timestamp' : df_train.timestamp[i], 'value': value_interpolation, 'is_anomaly' : 0.0},\n",
    "            ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ae05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_computing_max(X_train):\n",
    "    X_train_pred = model.predict(X_train, verbose=0)\n",
    "    train_mae_loss_avg = np.mean(np.abs(X_train_pred - X_train), axis=1)\n",
    "    max_threshold = np.max(train_mae_loss_avg)\n",
    "    return max_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e4295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss_predictions(X_test):\n",
    "    X_test_pred = model.predict(X_test, verbose=0)\n",
    "    mae_loss = np.mean(np.abs(X_test_pred-X_test), axis=1)\n",
    "    return mae_loss, X_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac4b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(mae_loss, threshold):\n",
    "    predicted_test_label = []\n",
    "    for i in range(0, len(test_mae_loss)):\n",
    "        if(test_mae_loss[i][0]>(threshold)):\n",
    "            predicted_test_label.append(1)\n",
    "        else:\n",
    "            predicted_test_label.append(0)\n",
    "    return predicted_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eebf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAB\n",
    "path_files = '../datasets/NAB_realAWSCloudwatch/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b714d4d",
   "metadata": {},
   "source": [
    "## Extract all file names corresponding to time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5156220",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_names = []\n",
    "for i in os.listdir(path_files):\n",
    "    ts_names.append(str(i.split('.csv')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb7b8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2_cpu_utilization_24ae8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17268/3065229697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mno_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     encdec = model.fit(X_train, X_train, epochs=no_epochs, batch_size=batch_size,\n\u001b[0;32m     53\u001b[0m                         validation_split=0.25).history\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17268/2280565355.py\u001b[0m in \u001b[0;36mlstm_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     L1 = LSTM(16, activation='relu', return_sequences=True, \n\u001b[1;32m----> 4\u001b[1;33m             kernel_regularizer=regularizers.l2(0.00))(inputs)\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mL2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mL3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oxifl\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oxifl\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oxifl\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oxifl\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                 raise ValueError('Layer ' + self.name + ' was called with '\n",
      "\u001b[1;32mc:\\Users\\oxifl\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \"\"\"\n\u001b[1;32m--> 695\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m    697\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oxifl\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_TensorLike\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'"
     ]
    }
   ],
   "source": [
    "df_final_results_details = pd.DataFrame(columns = ['TS_name', 'lstmae_reconstruction_loss'])\n",
    "df_final_results = pd.DataFrame(columns = ['TS_name', 'Labels_True', 'Labels_Pred', 'Test_Size', 'Model'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "for ts_name in tqdm(ts_names):\n",
    "    \n",
    "    print(ts_name)\n",
    "    # path to train/test\n",
    "    filename = path_files+ts_name+\".csv\"\n",
    "    \n",
    "    # read ts\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # split into train and test\n",
    "    init_train = df[0:math.floor(len(df)/2)]\n",
    "    init_test = df[math.floor(len(df)/2):]\n",
    "    \n",
    "    df_train = init_train\n",
    "    df_test = init_test\n",
    "    \n",
    "    \n",
    "    # remove anomalies from train to prepare LSTM\n",
    "    # all anomalies are replaced by the interpolation of their closest non-anomalous neighbours\n",
    "    df_train = train_anomaly_removal(df_train)\n",
    "    \n",
    "    \n",
    "    # final training dataset + labels\n",
    "    label_train = df_train.is_anomaly\n",
    "    train = df_train.value\n",
    "    \n",
    "\n",
    "    # final testing dataset + labels\n",
    "    label_test = df_test.is_anomaly\n",
    "    test = df_test.value\n",
    "    \n",
    "\n",
    "    # Data preprocessing - Scaling\n",
    "    # the scaler is fit on the training data and applied on the testing data\n",
    "    train_scale = scaler.fit_transform(np.array(train).reshape(-1, 1))\n",
    "    test_scale = scaler.transform(np.array(test).reshape(-1,1))\n",
    "    \n",
    "\n",
    "    # Shape Train Data for LSTM\n",
    "    X_train = train_scale.reshape(train_scale.shape[0], 1, 1)\n",
    "\n",
    "    # Train LSTM\n",
    "    no_epochs = 50\n",
    "    batch_size = 128\n",
    "    model = lstm_model()\n",
    "    encdec = model.fit(X_train, X_train, epochs=no_epochs, batch_size=batch_size,\n",
    "                        validation_split=0.25).history\n",
    "\n",
    "    # Threshold computing\n",
    "    threshold = threshold_computing_max(X_train)\n",
    "    \n",
    "    # Shape Test Data for LSTM\n",
    "    X_test = test_scale.reshape(test_scale.shape[0], 1, 1)\n",
    "    \n",
    "    test_mae_loss, X_test_pred = reconstruction_loss_predictions(X_test)\n",
    "    \n",
    "    # Extracting Predicted Labels\n",
    "    predicted_test_label = predicted_labels(test_mae_loss, threshold)\n",
    "    \n",
    "\n",
    "    # Save Results\n",
    "    # Save reconstruction Error for each Dataset\n",
    "    df_results_details = pd.DataFrame()\n",
    "    df_results_details['TS_name'] = [ts_name]\n",
    "    df_results_details['lstmae_reconstruction_loss'] = threshold\n",
    "    df_final_results_details = df_final_results_details.append(df_results_details)\n",
    "    \n",
    "    \n",
    "    # Save Predicted Labels\n",
    "    df_results = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    df_results['TS_name'] = [ts_name]\n",
    "    df_results['Labels_True'] = [list(label_test)]\n",
    "    df_results['Labels_Pred'] = [predicted_test_label]\n",
    "    df_results['Test_Size'] = len(list(label_test))\n",
    "    df_results['Model'] = 'LSTM_AE'\n",
    "    df_final_results = df_final_results.append(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "432513ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_results = df_final_results.set_index([pd.Index(np.arange(len(df_final_results))), 'TS_name'])\n",
    "df_final_results_details = df_final_results_details.set_index([pd.Index(np.arange(len(df_final_results_details))), 'TS_name'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
