{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433563b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4942eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import funcy\n",
    "import copy\n",
    "import random\n",
    "import antropy as ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0fcc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56005c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is helper method for TS rendering with datapoints\n",
    "# visualize FP and FN on time series\n",
    "def ts_confusion_visualization(data_test, pred_val, dataset, filename, modelname):\n",
    "    x, y, true_val = data_test['timestamp'].tolist(), data_test['value'].tolist(), data_test['is_anomaly'].tolist()\n",
    "    try:\n",
    "        x = [datetime.datetime.strptime(x, '%m/%d/%Y %H:%M') for x in x]\n",
    "    except:\n",
    "        try:\n",
    "            x = [datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S') for x in x]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    fp = [(x[i], y[i]) for i in range(len(true_val)) if true_val[i] == 0 and pred_val[i] == 1]\n",
    "    fn = [(x[i], y[i]) for i in range(len(true_val)) if true_val[i] == 1 and pred_val[i] == 0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, color='grey', lw=0.5, zorder=0)\n",
    "    ax.scatter([t[0] for t in fp], [t[1] for t in fp], color='r', s=5, zorder=5)\n",
    "    ax.scatter([t[0] for t in fn], [t[1] for t in fn], color='y', s=5, zorder=5)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color='k', lw=2, label='Correct'),\n",
    "                       Line2D([0], [0], marker='o', color='r', markersize=5, label='FP'),\n",
    "                       Line2D([0], [0], marker='o', color='y', markersize=5, label='FN')]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "    pyplot.savefig(f'../results/imgs/{modelname}_{dataset}_{filename}.png')\n",
    "    pyplot.clf()\n",
    "    pyplot.close('all')\n",
    "    plt.close('all')\n",
    "    del fig\n",
    "    del ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9e3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the indexes of non-anomalies for interpolation \n",
    "def interpolation_indexes(mylist, mynumber):\n",
    "    \n",
    "    left_neighbour = 0\n",
    "    right_neighbour = 0\n",
    "    \n",
    "    # check left neighbour\n",
    "    if((mynumber - 1) not in mylist):\n",
    "        left_neighbour = mynumber - 1\n",
    "    else:\n",
    "        min_number = mynumber\n",
    "        while min_number in mylist:\n",
    "            min_number = min_number - 1\n",
    "        left_neighbour = min_number\n",
    "    \n",
    "    # check right neighbour\n",
    "    if((mynumber + 1) not in mylist):\n",
    "        right_neighbour = mynumber + 1\n",
    "    else:\n",
    "        max_number = mynumber\n",
    "        while max_number in mylist:\n",
    "            max_number = max_number + 1\n",
    "        right_neighbour = max_number\n",
    "    \n",
    "    return left_neighbour, right_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5361d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anomaly_removal(df_train):\n",
    "    \n",
    "    # extract indexes for anomalies\n",
    "    indexes = list(df_train[df_train.is_anomaly == 1].index)\n",
    "\n",
    "    # creating a new df that replaces the anomalous samples with interpolation value\n",
    "    df = pd.DataFrame(columns = df_train.columns)\n",
    "    print(df_train.shape)\n",
    "    for i in range(0, df_train.shape[0]):\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        # add all non-anomalies\n",
    "        if df_train.is_anomaly[i] == 0:\n",
    "            df = df.append({'timestamp' : df_train.timestamp[i], 'value' : df_train.value[i], 'is_anomaly' : df_train.is_anomaly[i]},\n",
    "            ignore_index = True)\n",
    "\n",
    "        if df_train.is_anomaly[i] == 1:\n",
    "            if (i+1) < df_train.shape[0] and df_train.is_anomaly[i+1] != 1:\n",
    "                #print(i)\n",
    "                value_interpolation = (df_train.value[interpolation_indexes(indexes, i)[0]]+df_train.value[interpolation_indexes(indexes, i)[1]])/2\n",
    "\n",
    "                df = df.append({'timestamp' : df_train.timestamp[i], 'value': value_interpolation, 'is_anomaly' : 0.0},\n",
    "            ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238edff6",
   "metadata": {},
   "source": [
    "# Set hyperparameters for train flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e11bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pci'\n",
    "\n",
    "# decide on windwos with Lorena\n",
    "anomaly_window = 65\n",
    "test_window = 65\n",
    "for_optimization = False\n",
    "\n",
    "use_drift_adapt = False\n",
    "drift_detector = None\n",
    "use_entropy = False\n",
    "threshold_type = 'static'\n",
    "if use_entropy:\n",
    "    threshold_type = 'dynamic'\n",
    "\n",
    "# TODO discuss averaging\n",
    "# class averaging type for evaluation metrics calculations\n",
    "# Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "avg_type = None\n",
    "\n",
    "# allowed delay for anomaly shifts during evaluation\n",
    "evaluation_delay = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaca709",
   "metadata": {},
   "source": [
    "# Create FFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cbcb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.0\n",
      "['C:\\\\Users\\\\oxifl\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib\\\\site-packages\\\\numpy']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(2, '../utils/')\n",
    "# import importlib\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# sys.path.insert(0, os.path.abspath('../module-subdirectory'))\n",
    "\n",
    "from evaluation import label_evaluation\n",
    "from fft import detect_anomalies\n",
    "from dwt_mlead import DWT_MLEAD\n",
    "from pci import PCIAnomalyDetector\n",
    "\n",
    "# fft\n",
    "ifft_parameters: int = 5\n",
    "context_window_size: int = 21\n",
    "local_outlier_threshold: float = .6\n",
    "max_anomaly_window_size: int = 50\n",
    "max_sign_change_distance: int = 10\n",
    "random_state: int = 42\n",
    "\n",
    "# dwt mlead\n",
    "start_level: int = 3\n",
    "quantile_epsilon: float = 0.01\n",
    "random_state: int = 42\n",
    "use_column_index: int = 0\n",
    "\n",
    "# from the paper on their timeseries optimal (k,p)\n",
    "# flactuates around (5, 0.95) and (7, 0.97) so we take approx them\n",
    "window_size: int = 6\n",
    "thresholding_p: float = 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9ca88",
   "metadata": {},
   "source": [
    "# Import SR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92fd4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from msanomalydetector import THRESHOLD, MAG_WINDOW, SCORE_WINDOW\n",
    "from msanomalydetector import DetectMode\n",
    "from msanomalydetector.spectral_residual import SpectralResidual\n",
    "\n",
    "####################################################################################\n",
    "# this code is taken from\n",
    "# https://github.com/microsoft/anomalydetector\n",
    "# with modifications to account for sliding windows and entropy thresholding\n",
    "# the modified code is worj from:\n",
    "# https://github.com/nata1y/tiny-anom-det/tree/main/models/sr\n",
    "####################################################################################\n",
    "\n",
    "# initial parameters from the paper\n",
    "sr_model_params = (THRESHOLD, MAG_WINDOW, SCORE_WINDOW, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba1040",
   "metadata": {},
   "source": [
    "# Entropy threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4924391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrop test threshold ##########################################################\n",
    "def apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, threshold):\n",
    "    try:\n",
    "        entropy = ant.svd_entropy(window['value'].tolist(), normalize=True)\n",
    "    except:\n",
    "        entropy = (boundary_bottom + boundary_up) / 2\n",
    "\n",
    "    if entropy < boundary_bottom or entropy > boundary_up:\n",
    "        extent = stats.percentileofscore(svd_entropies, entropy) / 100.0\n",
    "        extent = 1.5 - max(extent, 1.0 - extent)\n",
    "        threshold *= extent\n",
    "    \n",
    "    predictions = [1 if a > threshold else 0 for a in anomaly_scores[-window.shape[0]:]]\n",
    "    return predictions\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e3842",
   "metadata": {},
   "source": [
    "# Entropy drift detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a13d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyhht\n",
    "# from drift_detection.detect_drift import DriftDetector\n",
    "# from drift_detection.ETFE import ETFE\n",
    "from drift_detection.FEDD import FEDD\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "# import rpy2.robjects as robjects\n",
    "# from rpy2.robjects import pandas2ri\n",
    "\n",
    "\n",
    "# class DriftDetectorT(ETFE):\n",
    "\n",
    "#     def __init__(self, entropy_type='SampEn'):\n",
    "#         super().__init__(entropy_type)\n",
    "#         entropy_delta = 0.6\n",
    "        \n",
    "\n",
    "#     def process_train_data(self, data):\n",
    "#         for point in data:\n",
    "#             entropy = self.feed(point)\n",
    "\n",
    "#     def is_drifted(self, window):\n",
    "#         entropies = []\n",
    "\n",
    "#         for point in window:\n",
    "#             entropy = self.feed(point)\n",
    "#             if entropy:\n",
    "#                 entropies.append(entropy)\n",
    "\n",
    "#         print(entropies)\n",
    "#         df = pd.DataFrame([])\n",
    "#         df['entropy'] = entropies\n",
    "#         df.to_csv('entropies.csv')\n",
    "#         if entropies:\n",
    "\n",
    "#             glr_test_stat = subprocess.call(\"Rscript GLR.R\", shell=True)\n",
    "#             print(glr_test_stat)\n",
    "# #             if glr_test_stat > self.entropy_delta:\n",
    "# #                 # drift occured\n",
    "# #                 return True\n",
    "#         return False\n",
    "    \n",
    "\n",
    "# dd = DriftDetectorT()\n",
    "dd = FEDD()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940e883",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b623d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpi\n",
      "My old F1 score is: 1.0\n",
      "My old F1 score is: 1.0\n",
      "My old F1 score is: 1.0\n",
      "My old F1 score is: 1.0\n",
      "My old F1 score is: 1.0\n",
      "My old F1 score is: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 'Yahoo_A1Benchmark', 'NAB_realAWSCloudwatch', 'kpi' \n",
    "# 'sliding_window', 'full_history', 'static'\n",
    "for model_name in ['sr']:\n",
    "    for dataset in ['kpi']:\n",
    "        print(dataset)\n",
    "        ds_res = {}\n",
    "        for training_type in ['static']:\n",
    "            act = 0\n",
    "            minl = float('inf')\n",
    "            maxlen = 0\n",
    "            # 'pci',  'dwt_mlead', 'fft', 'sr'\n",
    "\n",
    "\n",
    "            try:\n",
    "                stats_full = pd.read_csv(f'../results/scores/{model_name}_{dataset}_{training_type}_stats.csv')\n",
    "            except:\n",
    "                # set window size equals one week\n",
    "                # yahoo is hourly, nab and kpi are 5 minute\n",
    "                if dataset == 'Yahoo_A1Benchmark':\n",
    "                    anomaly_window = 168\n",
    "                else:\n",
    "                    anomaly_window = 1440\n",
    "\n",
    "                test_window = anomaly_window\n",
    "\n",
    "                if dataset == 'kpi':\n",
    "                    train_data_path = f'../datasets/kpi/train/'\n",
    "                else:\n",
    "                    train_data_path = f'../datasets/{dataset}/'\n",
    "\n",
    "                for filename in os.listdir(train_data_path):\n",
    "                    f = os.path.join(train_data_path, filename)\n",
    "                    data = pd.read_csv(f, engine='python')\n",
    "\n",
    "                    filename = filename.replace('.csv', '')\n",
    "                    # print(f'Working with current time series: {filename} in dataset {dataset}')\n",
    "\n",
    "                    data.rename(columns={'timestamps': 'timestamp', 'anomaly': 'is_anomaly'}, inplace=True)\n",
    "\n",
    "                    # timestamp preprocessing for kpi -- their are unix timestamps\n",
    "                    if dataset == 'kpi':\n",
    "                        data_test = pd.read_csv(os.path.join(f'../datasets/{dataset}/test/', filename + '.csv'))\n",
    "                        data_test['timestamp'] = data_test['timestamp'].apply(\n",
    "                            lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                        data['timestamp'] = data['timestamp'].apply(\n",
    "                            lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "                        # kpi stores train and test in different ts -- merge them into one to follow structure\n",
    "                        data = pd.concat([data, data_test], ignore_index=True)\n",
    "\n",
    "                    # 50-50 train/test split\n",
    "                    data_train, data_test = np.array_split(data, 2)\n",
    "\n",
    "                    minl = min(minl, data.shape[0])\n",
    "                    maxlen = max(maxlen, data.shape[0])\n",
    "                    act += data['is_anomaly'].tolist().count(1)\n",
    "                    \n",
    "                    if data_test['is_anomaly'].tolist().count(1) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # set (re)training (== application) windwos based on type\n",
    "                    if training_type == 'static':\n",
    "                        data_in_memory_size = anomaly_window\n",
    "                        pci_window = anomaly_window\n",
    "                    elif training_type == 'sliding_window':\n",
    "                        data_in_memory_size = data_train.shape[0]\n",
    "                        pci_window = data_train.shape[0]\n",
    "                    elif training_type == 'full_history':\n",
    "                        data_in_memory_size = 0\n",
    "\n",
    "                    # train model #######################################################################################\n",
    "                    start = time.time()\n",
    "                    fft_threshold = 0\n",
    "\n",
    "                    if model_name == 'fft':\n",
    "                        # since no threshold is provided, we are using the max on de-anomalized training set\n",
    "                        # same tichnique is sued in dynamic models\n",
    "                        data_train = train_anomaly_removal(data_train)\n",
    "                        model = detect_anomalies\n",
    "                        random.seed(random_state)\n",
    "                        np.random.seed(random_state)\n",
    "                        anomaly_scores = model(\n",
    "                                        data_train['value'].to_numpy(),\n",
    "                                        max_region_size=max_anomaly_window_size,\n",
    "                                        local_neighbor_window=context_window_size\n",
    "                                    )\n",
    "                        fft_threshold = max(anomaly_scores)\n",
    "                    elif model_name == 'pci':\n",
    "                        model = PCIAnomalyDetector(\n",
    "                            k=pci_window // 2,\n",
    "                            p=thresholding_p,\n",
    "                            calculate_labels=True\n",
    "                        )\n",
    "                    elif model_name == 'sr':\n",
    "                        model = SpectralResidual(series=data_train[['value', 'timestamp']], use_drift=use_drift_adapt,\n",
    "                                        threshold=sr_model_params[0], mag_window=sr_model_params[1],\n",
    "                                        score_window=sr_model_params[2], sensitivity=sr_model_params[3],\n",
    "                                        detect_mode=DetectMode.anomaly_only, dataset=dataset,\n",
    "                                        filename=filename, drift_detector=drift_detector,\n",
    "                                        data_in_memory_sz=data_in_memory_size, anomaly_window=anomaly_window)\n",
    "                        model.fit()\n",
    "\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    diff = end_time - start\n",
    "\n",
    "                    # (entropy) drift detection ##########################################################################\n",
    "                    # dd.process_train_data(data_train['value'].tolist())\n",
    "\n",
    "                    # drift detection ####################################################################################\n",
    "\n",
    "#                     dd.train_wrapper(data_train['value'].tolist())\n",
    "\n",
    "                    # entropy fitting ####################################################################################\n",
    "                    svd_entropies = []\n",
    "                    entropy_factor = 1.5\n",
    "                    \n",
    "#                     for start in range(0, data_train.shape[0], anomaly_window):\n",
    "#                         try:\n",
    "#                             svd_entropies.append(\n",
    "#                                 ant.svd_entropy(data_train[start:start + anomaly_window]['value'].tolist(),\n",
    "#                                                 normalize=True))\n",
    "#                         except Exception as e:\n",
    "#                             print(str(e))\n",
    "                    \n",
    "#                     mean_entropy = np.mean([v for v in svd_entropies if pd.notna(v)])\n",
    "#                     boundary_bottom = mean_entropy - \\\n",
    "#                                         entropy_factor * \\\n",
    "#                                         np.std([v for v in svd_entropies if pd.notna(v)])\n",
    "#                     boundary_up = mean_entropy + \\\n",
    "#                                     entropy_factor * \\\n",
    "#                                     np.std([v for v in svd_entropies if pd.notna(v)])\n",
    "\n",
    "                    # test model #########################################################################################\n",
    "\n",
    "                    batch_metrices_f1_entropy = []\n",
    "                    batch_metrices_f1_no_entropy = []\n",
    "                    y_pred_total_no_entropy, y_pred_total_entropy = [], []\n",
    "                    batches_with_anomalies = []\n",
    "                    idx = 0\n",
    "\n",
    "                    pred_time = []\n",
    "\n",
    "                    if for_optimization:\n",
    "                        data_in_memory = pd.DataFrame([])\n",
    "                    else:\n",
    "                        data_in_memory = copy.deepcopy(data_train)\n",
    "\n",
    "                    for start in range(0, data_test.shape[0], anomaly_window):\n",
    "                        try:\n",
    "                            # current window on which TESTING and SCORING is applied\n",
    "                            window = data_test.iloc[start:start + anomaly_window]\n",
    "                            # data hold in memory, calculations and predictions are performed across this window\n",
    "                            data_in_memory = pd.concat([data_in_memory, window])[-data_in_memory_size:]\n",
    "\n",
    "                            X, y = window['value'], window['is_anomaly']\n",
    "                            # (entropy) drift detection ##########################################################################\n",
    "#                             if dd.test_wrapper(X.tolist()):\n",
    "#                                 # RETRAIN HERE: returns true if drift detected within window\n",
    "#                                 print(f'DETECTED DRIFT IN WINDOW {start}!!!')\n",
    "\n",
    "                            ######################################################################################################\n",
    "\n",
    "                            if model_name == 'fft':\n",
    "                                anomaly_scores = model(\n",
    "                                    data_in_memory['value'].to_numpy(),\n",
    "                                    max_region_size=max_anomaly_window_size,\n",
    "                                    local_neighbor_window=context_window_size\n",
    "                                )\n",
    "                                # paper does not provide any way to detect anomaly threshold.\n",
    "                                # we use same as for lstm\n",
    "                                y_pred_noe = [1 if x > fft_threshold else 0 for x in anomaly_scores[-window.shape[0]:]]\n",
    "                                # y_pred_e = apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, fft_threshold)\n",
    "                            elif model_name == 'sr':\n",
    "                                model.__series__ = data_in_memory\n",
    "                                res = model.predict(data_in_memory, window.shape[0])\n",
    "                                y_pred_noe = [1 if x else 0 for x in res['isAnomaly'].tolist()]\n",
    "                                # y_pred_e = [1 if x else 0 for x in res['isAnomaly_e'].tolist()]\n",
    "                            elif model_name == 'dwt_mlead':\n",
    "                                # FROM PAPER: \n",
    "                                # We empirically determined the setting l = 5 for the NAB data and l = 7 for the A3 data\n",
    "                                if 'NAB' in dataset:\n",
    "                                    start_level = 5\n",
    "                                elif 'Yahoo' in dataset:\n",
    "                                    start_level = 7\n",
    "                                model = DWT_MLEAD(data_in_memory['value'].to_numpy(),\n",
    "                                    start_level=start_level,\n",
    "                                    quantile_boundary_type=\"percentile\",\n",
    "                                    quantile_epsilon=quantile_epsilon,\n",
    "                                    track_coefs=True\n",
    "                                )\n",
    "                                anomaly_scores = model.detect()\n",
    "                                # FROM PAPER: \n",
    "                                # We empirically determined the setting B = 3.5 for the NAB data and B = 1 for the A3 data\n",
    "                                threshold = 1\n",
    "                                if 'NAB' in dataset:\n",
    "                                    threshold =  3.5\n",
    "                                y_pred_noe = [1 if x > threshold else 0 for x in anomaly_scores[-window.shape[0]:]]\n",
    "                                # y_pred_e = apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, threshold)\n",
    "                            elif model_name == 'pci':\n",
    "                                model = PCIAnomalyDetector(\n",
    "                                    k=data_in_memory.shape[0] // 2,\n",
    "                                    p=thresholding_p,\n",
    "                                    calculate_labels=True\n",
    "                                )\n",
    "                                anomaly_scores, anomaly_labels = model.detect(data_in_memory['value'].to_numpy())\n",
    "                                y_pred_noe = anomaly_labels[-window.shape[0]:]\n",
    "                                # y_pred_e = apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, fft_threshold)\n",
    "\n",
    "                            idx += 1\n",
    "                            y_pred_total_no_entropy += [0 if val != 1 else 1 for val in funcy.lflatten(y_pred_noe)][:window.shape[0]]\n",
    "                            # y_pred_total_entropy += [0 if val != 1 else 1 for val in funcy.lflatten(y_pred_e)][:window.shape[0]]\n",
    "                            y_pred_noe = y_pred_noe[:window.shape[0]]\n",
    "                            # y_pred_e = y_pred_noe[:window.shape[0]]\n",
    "\n",
    "                        except Exception as e:\n",
    "                            raise e\n",
    "\n",
    "                    # calculate batched metrics per *test_window*\n",
    "                    # for test stats we calculate F1 score for eacj class but use score for anomaly label \n",
    "                    # this works because we have binary classification\n",
    "                    data_reset = data_test.reset_index()['is_anomaly']\n",
    "                    for i in range(0, len(data_test['is_anomaly']), test_window):\n",
    "                        # here, met_total will be (precision, recall, f1_score, support)\n",
    "\n",
    "                        met_total = precision_recall_fscore_support(data_reset[i:i+test_window],\n",
    "                                                                    y_pred_total_no_entropy[:data_test.shape[0]][i:i+test_window])\n",
    "                        batch_metrices_f1_no_entropy.append(met_total[2][-1])\n",
    "\n",
    "                    score = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                                                      y_pred_total_no_entropy[:data_test.shape[0]], 0)\n",
    "                    # score_entropy = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                    #                                   y_pred_total_entropy[:data_test.shape[0]], 0)\n",
    "\n",
    "                    # add entry to stats #######################################################################################\n",
    "\n",
    "                    try:\n",
    "                        stats_full = pd.read_csv(f'../results/scores/{model_name}_{dataset}_{training_type}_stats.csv')\n",
    "                    except:\n",
    "                        stats_full = pd.DataFrame([])\n",
    "                        \n",
    "                    res = {\n",
    "                        'model': model_name,\n",
    "                        'ts_name': filename,\n",
    "                        'precision': met_total[0][-1],\n",
    "                        'recall': met_total[1][-1],\n",
    "#                         'window': anomaly_window,\n",
    "#                         'delay': evaluation_delay,\n",
    "                        # 'f1_score_entropy': score_entropy,\n",
    "                        # 'f1_score_entropy_smoothed': smoothed_score_entropy,\n",
    "#                         'labels_true': data_test['is_anomaly'].tolist(),\n",
    "#                         'labels_pred': y_pred_total_no_entropy[:data_test.shape[0]]\n",
    "\n",
    "                    }\n",
    "                    \n",
    "                    for delay in range(8):\n",
    "                        res[f'f1_score_{delay}'] = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                                                      y_pred_total_no_entropy[:data_test.shape[0]], delay)\n",
    "\n",
    "#                     smoothed_score = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "#                                                       y_pred_total_no_entropy[:data_test.shape[0]], evaluation_delay)\n",
    "                    # smoothed_score_entropy = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                    #                                   y_pred_total_entropy[:data_test.shape[0]], evaluation_delay)\n",
    "#                     print(f'Smoothed F1 score is: {smoothed_score}')\n",
    "\n",
    "                    stats_full = stats_full.append(res, ignore_index=True)\n",
    "                    stats_full.to_csv(f'../results/scores/{model_name}_{dataset}_{training_type}_stats.csv', index=False)\n",
    "                    print(f'My old F1 score is: {met_total[2][-1]}')\n",
    "\n",
    "                    # plotting ##################################################################################################\n",
    "                    # general on ts\n",
    "                    if use_entropy:\n",
    "                        ts_confusion_visualization(data_test, y_pred_total_entropy, dataset, filename, model_name)\n",
    "                    else:\n",
    "                        ts_confusion_visualization(data_test, y_pred_total_no_entropy, dataset, filename, model_name)\n",
    "#                 print(act, minl, maxlen, dataset)I\n",
    "        # McNemar ############################################################################################\n",
    "#         from statsmodels.stats.contingency_tables import mcnemar\n",
    "#         for tp, labels in ds_res.items():\n",
    "#             for tp2, labels2 in ds_res.items():\n",
    "#                 if tp != tp2:\n",
    "#                     print(tp, tp2)\n",
    "#                     result = mcnemar([labels, labels2], exact=True)\n",
    "#                     # summarize the finding\n",
    "#                     print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "#                     # interpret the p-value\n",
    "#                     alpha = 0.05\n",
    "#                     if result.pvalue > alpha:\n",
    "#                         print('Same proportions of errors (fail to reject H0)')\n",
    "#                     else:\n",
    "#                         print('Different proportions of errors (reject H0)')\n",
    "        # evaluate TS ########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76479262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ab3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "df10a3505701b17119fcb7e3d7f2d07794f5df50b37fdb5d4118a55945757b43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
