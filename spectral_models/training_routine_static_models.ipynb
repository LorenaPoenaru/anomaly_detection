{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433563b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4942eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import funcy\n",
    "import copy\n",
    "import random\n",
    "import antropy as ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0fcc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56005c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is helper method for TS rendering with datapoints\n",
    "# visualize FP and FN on time series\n",
    "def ts_confusion_visualization(data_test, pred_val, dataset, filename, modelname):\n",
    "    x, y, true_val = data_test['timestamp'].tolist(), data_test['value'].tolist(), data_test['is_anomaly'].tolist()\n",
    "    try:\n",
    "        x = [datetime.datetime.strptime(x, '%m/%d/%Y %H:%M') for x in x]\n",
    "    except:\n",
    "        try:\n",
    "            x = [datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S') for x in x]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    fp = [(x[i], y[i]) for i in range(len(true_val)) if true_val[i] == 0 and pred_val[i] == 1]\n",
    "    fn = [(x[i], y[i]) for i in range(len(true_val)) if true_val[i] == 1 and pred_val[i] == 0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, color='grey', lw=0.5, zorder=0)\n",
    "    ax.scatter([t[0] for t in fp], [t[1] for t in fp], color='r', s=5, zorder=5)\n",
    "    ax.scatter([t[0] for t in fn], [t[1] for t in fn], color='y', s=5, zorder=5)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color='k', lw=2, label='Correct'),\n",
    "                       Line2D([0], [0], marker='o', color='r', markersize=5, label='FP'),\n",
    "                       Line2D([0], [0], marker='o', color='y', markersize=5, label='FN')]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "    pyplot.savefig(f'../results/imgs/{modelname}_{dataset}_{filename}.png')\n",
    "    pyplot.clf()\n",
    "    pyplot.close('all')\n",
    "    plt.close('all')\n",
    "    del fig\n",
    "    del ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9e3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the indexes of non-anomalies for interpolation \n",
    "def interpolation_indexes(mylist, mynumber):\n",
    "    \n",
    "    left_neighbour = 0\n",
    "    right_neighbour = 0\n",
    "    \n",
    "    # check left neighbour\n",
    "    if((mynumber - 1) not in mylist):\n",
    "        left_neighbour = mynumber - 1\n",
    "    else:\n",
    "        min_number = mynumber\n",
    "        while min_number in mylist:\n",
    "            min_number = min_number - 1\n",
    "        left_neighbour = min_number\n",
    "    \n",
    "    # check right neighbour\n",
    "    if((mynumber + 1) not in mylist):\n",
    "        right_neighbour = mynumber + 1\n",
    "    else:\n",
    "        max_number = mynumber\n",
    "        while max_number in mylist:\n",
    "            max_number = max_number + 1\n",
    "        right_neighbour = max_number\n",
    "    \n",
    "    return left_neighbour, right_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5361d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_anomaly_removal(df_train):\n",
    "    \n",
    "    # extract indexes for anomalies\n",
    "    indexes = list(df_train[df_train.is_anomaly == 1].index)\n",
    "\n",
    "    # creating a new df that replaces the anomalous samples with interpolation value\n",
    "    df = pd.DataFrame(columns = df_train.columns)\n",
    "    print(df_train.shape)\n",
    "    for i in range(0, df_train.shape[0]):\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        # add all non-anomalies\n",
    "        if df_train.is_anomaly[i] == 0:\n",
    "            df = df.append({'timestamp' : df_train.timestamp[i], 'value' : df_train.value[i], 'is_anomaly' : df_train.is_anomaly[i]},\n",
    "            ignore_index = True)\n",
    "\n",
    "        if df_train.is_anomaly[i] == 1:\n",
    "            if (i+1) < df_train.shape[0] and df_train.is_anomaly[i+1] != 1:\n",
    "                #print(i)\n",
    "                value_interpolation = (df_train.value[interpolation_indexes(indexes, i)[0]]+df_train.value[interpolation_indexes(indexes, i)[1]])/2\n",
    "\n",
    "                df = df.append({'timestamp' : df_train.timestamp[i], 'value': value_interpolation, 'is_anomaly' : 0.0},\n",
    "            ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238edff6",
   "metadata": {},
   "source": [
    "# Set hyperparameters for train flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e11bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pci'\n",
    "\n",
    "# decide on windwos with Lorena\n",
    "anomaly_window = 65\n",
    "test_window = 65\n",
    "for_optimization = False\n",
    "\n",
    "use_drift_adapt = False\n",
    "drift_detector = None\n",
    "use_entropy = False\n",
    "threshold_type = 'static'\n",
    "if use_entropy:\n",
    "    threshold_type = 'dynamic'\n",
    "\n",
    "# TODO discuss averaging\n",
    "# class averaging type for evaluation metrics calculations\n",
    "# Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "avg_type = None\n",
    "\n",
    "# allowed delay for anomaly shifts during evaluation\n",
    "evaluation_delay = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaca709",
   "metadata": {},
   "source": [
    "# Create FFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cbcb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.0\n",
      "['C:\\\\Users\\\\oxifl\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib\\\\site-packages\\\\numpy']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(2, '../utils/')\n",
    "\n",
    "from evaluation import label_evaluation\n",
    "from fft import detect_anomalies\n",
    "from dwt_mlead import DWT_MLEAD\n",
    "from pci import PCIAnomalyDetector\n",
    "\n",
    "# fft\n",
    "ifft_parameters: int = 5\n",
    "context_window_size: int = 21\n",
    "local_outlier_threshold: float = .6\n",
    "max_anomaly_window_size: int = 50\n",
    "max_sign_change_distance: int = 10\n",
    "random_state: int = 42\n",
    "\n",
    "# dwt mlead\n",
    "start_level: int = 3\n",
    "quantile_epsilon: float = 0.01\n",
    "random_state: int = 42\n",
    "use_column_index: int = 0\n",
    "\n",
    "# from the paper on their timeseries optimal (k,p)\n",
    "# flactuates around (5, 0.95) and (7, 0.97) so we take approx them\n",
    "window_size: int = 6\n",
    "thresholding_p: float = 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9ca88",
   "metadata": {},
   "source": [
    "# Import SR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92fd4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from msanomalydetector import THRESHOLD, MAG_WINDOW, SCORE_WINDOW\n",
    "from msanomalydetector import DetectMode\n",
    "from msanomalydetector.spectral_residual import SpectralResidual\n",
    "\n",
    "####################################################################################\n",
    "# this code is taken from\n",
    "# https://github.com/microsoft/anomalydetector\n",
    "# with modifications to account for sliding windows and entropy thresholding\n",
    "# the modified code is worj from:\n",
    "# https://github.com/nata1y/tiny-anom-det/tree/main/models/sr\n",
    "####################################################################################\n",
    "\n",
    "# initial parameters from the paper\n",
    "sr_model_params = (THRESHOLD, MAG_WINDOW, SCORE_WINDOW, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba1040",
   "metadata": {},
   "source": [
    "# Entropy threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4924391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrop test threshold ##########################################################\n",
    "def apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, threshold):\n",
    "    try:\n",
    "        entropy = ant.svd_entropy(window['value'].tolist(), normalize=True)\n",
    "    except:\n",
    "        entropy = (boundary_bottom + boundary_up) / 2\n",
    "\n",
    "    if entropy < boundary_bottom or entropy > boundary_up:\n",
    "        extent = stats.percentileofscore(svd_entropies, entropy) / 100.0\n",
    "        extent = 1.5 - max(extent, 1.0 - extent)\n",
    "        threshold *= extent\n",
    "    \n",
    "    predictions = [1 if a > threshold else 0 for a in anomaly_scores[-window.shape[0]]]\n",
    "    return predictions\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940e883",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b623d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with current time series: real_1 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_10 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_11 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.1904761904761905\n",
      "Working with current time series: real_12 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.5714285714285715\n",
      "My old F1 score is: 0.3333333333333333\n",
      "Working with current time series: real_13 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 1.0\n",
      "My old F1 score is: 0.3636363636363636\n",
      "Working with current time series: real_14 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_15 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 1.0\n",
      "My old F1 score is: 0.4\n",
      "Working with current time series: real_16 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8571428571428571\n",
      "My old F1 score is: 0.6666666666666666\n",
      "Working with current time series: real_17 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.6647230320699709\n",
      "My old F1 score is: 0.01731601731601732\n",
      "Working with current time series: real_18 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_19 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.6512968299711815\n",
      "My old F1 score is: 0.04184100418410042\n",
      "Working with current time series: real_2 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.761904761904762\n",
      "My old F1 score is: 0.3225806451612903\n",
      "Working with current time series: real_20 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8571428571428571\n",
      "My old F1 score is: 0.2857142857142857\n",
      "Working with current time series: real_21 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.6666666666666667\n",
      "My old F1 score is: 0.4615384615384615\n",
      "Working with current time series: real_22 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.9767441860465117\n",
      "My old F1 score is: 0.029850746268656716\n",
      "Working with current time series: real_23 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_24 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.125\n",
      "My old F1 score is: 0.125\n",
      "Working with current time series: real_25 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8431372549019608\n",
      "My old F1 score is: 0.03333333333333333\n",
      "Working with current time series: real_26 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_27 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 1.0\n",
      "My old F1 score is: 1.0\n",
      "Working with current time series: real_28 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.024096385542168672\n",
      "My old F1 score is: 0.024096385542168672\n",
      "Working with current time series: real_29 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.6153846153846153\n",
      "My old F1 score is: 0.5\n",
      "Working with current time series: real_3 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.9655172413793104\n",
      "My old F1 score is: 0.125\n",
      "Working with current time series: real_30 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.9411764705882353\n",
      "My old F1 score is: 0.2\n",
      "Working with current time series: real_31 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.06666666666666667\n",
      "My old F1 score is: 0.06666666666666667\n",
      "Working with current time series: real_32 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.04\n",
      "Working with current time series: real_33 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.5714285714285715\n",
      "My old F1 score is: 0.3333333333333333\n",
      "Working with current time series: real_34 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8333333333333334\n",
      "My old F1 score is: 0.4444444444444444\n",
      "Working with current time series: real_35 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_36 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_37 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.7816091954022989\n",
      "My old F1 score is: 0.07272727272727271\n",
      "Working with current time series: real_38 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8571428571428571\n",
      "My old F1 score is: 0.2222222222222222\n",
      "Working with current time series: real_39 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_4 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.4444444444444444\n",
      "My old F1 score is: 0.25000000000000006\n",
      "Working with current time series: real_40 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_41 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.2222222222222222\n",
      "My old F1 score is: 0.2222222222222222\n",
      "Working with current time series: real_42 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.32786885245901637\n",
      "My old F1 score is: 0.038461538461538464\n",
      "Working with current time series: real_43 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.1818181818181818\n",
      "My old F1 score is: 0.1818181818181818\n",
      "Working with current time series: real_44 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_45 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.25\n",
      "My old F1 score is: 0.25\n",
      "Working with current time series: real_46 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.03603603603603604\n",
      "My old F1 score is: 0.03603603603603604\n",
      "Working with current time series: real_47 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.33333333333333337\n",
      "My old F1 score is: 0.33333333333333337\n",
      "Working with current time series: real_48 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_49 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_5 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_50 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 1.0\n",
      "My old F1 score is: 0.25\n",
      "Working with current time series: real_51 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.5\n",
      "My old F1 score is: 0.5\n",
      "Working with current time series: real_52 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8750000000000001\n",
      "My old F1 score is: 0.3636363636363636\n",
      "Working with current time series: real_53 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.125\n",
      "My old F1 score is: 0.125\n",
      "Working with current time series: real_54 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_55 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.4\n",
      "My old F1 score is: 0.4\n",
      "Working with current time series: real_56 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.22222222222222224\n",
      "My old F1 score is: 0.22222222222222224\n",
      "Working with current time series: real_57 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_58 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_59 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_6 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_60 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.8148148148148148\n",
      "My old F1 score is: 0.3157894736842105\n",
      "Working with current time series: real_61 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.5\n",
      "My old F1 score is: 0.5\n",
      "Working with current time series: real_62 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.4444444444444445\n",
      "My old F1 score is: 0.4444444444444445\n",
      "Working with current time series: real_63 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_64 in dataset Yahoo_A1Benchmark\n",
      "Working with current time series: real_65 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_66 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.30769230769230765\n",
      "My old F1 score is: 0.044444444444444446\n",
      "Working with current time series: real_67 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_7 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.0\n",
      "My old F1 score is: 0.0\n",
      "Working with current time series: real_8 in dataset Yahoo_A1Benchmark\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed F1 score is: 0.3\n",
      "My old F1 score is: 0.3\n",
      "Working with current time series: real_9 in dataset Yahoo_A1Benchmark\n",
      "Smoothed F1 score is: 0.75\n",
      "My old F1 score is: 0.5714285714285715\n",
      "Working with current time series: real_1 in dataset Yahoo_A1Benchmark\n",
      "Gaussion Distribution for level 7:\n",
      "Shapes: mean=(2,), covariance=(2, 2), p=(1,)\n",
      "Gaussion Distribution for level 7:\n",
      "Shapes: mean=(2,), covariance=(2, 2), p=(1,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2964/1448007135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mstats_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../results/scores/{model_name}_{dataset}_{training_type}_stats_entropy.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/scores/dwt_mlead_Yahoo_A1Benchmark_static_stats_entropy.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2964/1448007135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m                     \u001b[1;31m# evaluate TS ########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2964/1448007135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    175\u001b[0m                                         \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m3.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                                     \u001b[0my_pred_noe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manomaly_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                                     \u001b[0my_pred_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_entropy_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvd_entropies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_bottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_up\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manomaly_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m                                 \u001b[1;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pci'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                                     \u001b[0manomaly_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manomaly_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_in_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2964/543613952.py\u001b[0m in \u001b[0;36mapply_entropy_threshold\u001b[1;34m(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, threshold)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mextent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manomaly_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m##################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# 'Yahoo_A1Benchmark', 'NAB_realAWSCloudwatch', 'kpi'\n",
    "for dataset in ['Yahoo_A1Benchmark', 'NAB_realAWSCloudwatch', 'NAB_realAWSCloudwatch_window']:\n",
    "    for training_type in ['static', 'sliding_window', 'full_history']:\n",
    "        # 'sr', 'pci', 'fft'\n",
    "        for model_name in ['sr', 'dwt_mlead', 'fft']:\n",
    "            \n",
    "            try:\n",
    "                stats_full = pd.read_csv(f'../results/scores/{model_name}_{dataset}_{training_type}_stats_entropy.csv')\n",
    "            except:\n",
    "                # set window size equals one week\n",
    "                # yahoo is hourly, nab and kpi are 5 minute\n",
    "                if dataset == 'Yahoo_A1Benchmark':\n",
    "                    anomaly_window = 168\n",
    "                else:\n",
    "                    anomaly_window = 2016\n",
    "                # anomaly_window = 65\n",
    "\n",
    "                test_window = anomaly_window\n",
    "\n",
    "                if dataset == 'kpi':\n",
    "                    train_data_path = f'../datasets/kpi/train/'\n",
    "                else:\n",
    "                    train_data_path = f'../datasets/{dataset}/'\n",
    "\n",
    "                for filename in os.listdir(train_data_path):\n",
    "                    f = os.path.join(train_data_path, filename)\n",
    "                    data = pd.read_csv(f, engine='python')\n",
    "\n",
    "                    filename = filename.replace('.csv', '')\n",
    "                    print(f'Working with current time series: {filename} in dataset {dataset}')\n",
    "\n",
    "                    data.rename(columns={'timestamps': 'timestamp', 'anomaly': 'is_anomaly'}, inplace=True)\n",
    "    #                 data.drop_duplicates(subset=['timestamp'], keep=False, inplace=True)\n",
    "\n",
    "                    # timestamp preprocessing for kpi -- their are unix timestamps\n",
    "                    if dataset == 'kpi':\n",
    "                        data_test = pd.read_csv(os.path.join(f'../datasets/{dataset}/test/', filename + '.csv'))\n",
    "                        data_test['timestamp'] = data_test['timestamp'].apply(\n",
    "                            lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                        data['timestamp'] = data['timestamp'].apply(\n",
    "                            lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "                        # kpi stores train and test in different ts -- merge them into one to follow structure\n",
    "                        data = pd.concat([data, data_test], ignore_index=True)\n",
    "\n",
    "                    # 50-50 train/test split\n",
    "                    data_train, data_test = np.array_split(data, 2)\n",
    "                    \n",
    "                    if data_test['is_anomaly'].tolist().count(1) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # set (re)training (== application) windwos based on type\n",
    "                    if training_type == 'static':\n",
    "                        data_in_memory_size = anomaly_window\n",
    "                    elif training_type == 'sliding_window':\n",
    "                        data_in_memory_size = data_train.shape[0]\n",
    "                    elif training_type == 'full_history':\n",
    "                        data_in_memory_size = 0\n",
    "\n",
    "\n",
    "                    # train model #######################################################################################\n",
    "                    start = time.time()\n",
    "                    fft_threshold = 0\n",
    "\n",
    "                    if model_name == 'fft':\n",
    "                        # since no threshold is provided, we are using the max on de-anomalized training set\n",
    "                        # same tichnique is sued in dynamic models\n",
    "                        data_train = train_anomaly_removal(data_train)\n",
    "                        model = detect_anomalies\n",
    "                        random.seed(random_state)\n",
    "                        np.random.seed(random_state)\n",
    "                        anomaly_scores = model(\n",
    "                                        data_train['value'].to_numpy(),\n",
    "                                        max_region_size=max_anomaly_window_size,\n",
    "                                        local_neighbor_window=context_window_size\n",
    "                                    )\n",
    "                        fft_threshold = max(anomaly_scores)\n",
    "                    elif model_name == 'pci':\n",
    "                        model = PCIAnomalyDetector(\n",
    "                            k=window_size // 2,\n",
    "                            p=thresholding_p,\n",
    "                            calculate_labels=False\n",
    "                        )\n",
    "                    elif model_name == 'sr':\n",
    "                        model = SpectralResidual(series=data_train[['value', 'timestamp']], use_drift=use_drift_adapt,\n",
    "                                        threshold=sr_model_params[0], mag_window=sr_model_params[1],\n",
    "                                        score_window=sr_model_params[2], sensitivity=sr_model_params[3],\n",
    "                                        detect_mode=DetectMode.anomaly_only, dataset=dataset,\n",
    "                                        filename=filename, drift_detector=drift_detector,\n",
    "                                        data_in_memory_sz=data_in_memory_size, anomaly_window=anomaly_window)\n",
    "                        model.fit()\n",
    "\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    diff = end_time - start\n",
    "\n",
    "                    # entropy fitting ####################################################################################\n",
    "                    svd_entropies = []\n",
    "                    entropy_factor = 1.5\n",
    "\n",
    "                    for start in range(0, data_train.shape[0], anomaly_window):\n",
    "                        try:\n",
    "                            svd_entropies.append(\n",
    "                                ant.svd_entropy(data_train[start:start + anomaly_window]['value'].tolist(),\n",
    "                                                normalize=True))\n",
    "                        except Exception as e:\n",
    "                            print(str(e))\n",
    "                    \n",
    "                    mean_entropy = np.mean([v for v in svd_entropies if pd.notna(v)])\n",
    "                    boundary_bottom = mean_entropy - \\\n",
    "                                        entropy_factor * \\\n",
    "                                        np.std([v for v in svd_entropies if pd.notna(v)])\n",
    "                    boundary_up = mean_entropy + \\\n",
    "                                    entropy_factor * \\\n",
    "                                    np.std([v for v in svd_entropies if pd.notna(v)])\n",
    "\n",
    "                    # test model #########################################################################################\n",
    "\n",
    "                    batch_metrices_f1_entropy = []\n",
    "                    batch_metrices_f1_no_entropy = []\n",
    "                    y_pred_total_no_entropy, y_pred_total_entropy = [], []\n",
    "                    batches_with_anomalies = []\n",
    "                    idx = 0\n",
    "\n",
    "                    pred_time = []\n",
    "\n",
    "                    if for_optimization:\n",
    "                        data_in_memory = pd.DataFrame([])\n",
    "                    else:\n",
    "                        data_in_memory = copy.deepcopy(data_train)\n",
    "\n",
    "                    for start in range(0, data_test.shape[0], anomaly_window):\n",
    "                        try:\n",
    "                            # current window on which TESTING and SCORING is applied\n",
    "                            window = data_test.iloc[start:start + anomaly_window]\n",
    "                            # data hold in memory, calculations and predictions are performed across this window\n",
    "                            data_in_memory = pd.concat([data_in_memory, window])[-data_in_memory_size:]\n",
    "\n",
    "                            X, y = window['value'], window['is_anomaly']\n",
    "                            if y.tolist():\n",
    "\n",
    "                                if model_name == 'fft':\n",
    "                                    anomaly_scores = model(\n",
    "                                        data_in_memory['value'].to_numpy(),\n",
    "                                        max_region_size=max_anomaly_window_size,\n",
    "                                        local_neighbor_window=context_window_size\n",
    "                                    )\n",
    "                                    # paper does not provide any way to detect anomaly threshold.\n",
    "                                    # we use same as for lstm\n",
    "                                    y_pred_noe = [1 if x > fft_threshold else 0 for x in anomaly_scores[-window.shape[0]:]]\n",
    "                                    y_pred_e = apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, fft_threshold)\n",
    "                                elif model_name == 'sr':\n",
    "                                    model.__series__ = data_in_memory\n",
    "                                    res = model.predict(data_in_memory, window.shape[0])\n",
    "                                    y_pred_noe = [1 if x else 0 for x in res['isAnomaly'].tolist()]\n",
    "                                    y_pred_e = [1 if x else 0 for x in res['isAnomaly_e'].tolist()]\n",
    "                                elif model_name == 'dwt_mlead':\n",
    "                                    # FROM PAPER: \n",
    "                                    # We empirically determined the setting l = 5 for the NAB data and l = 7 for the A3 data\n",
    "                                    if 'NAB' in dataset:\n",
    "                                        start_level = 5\n",
    "                                    elif 'Yahoo' in dataset:\n",
    "                                        start_level = 7\n",
    "                                    model = DWT_MLEAD(data_in_memory['value'].to_numpy(),\n",
    "                                        start_level=start_level,\n",
    "                                        quantile_boundary_type=\"percentile\",\n",
    "                                        quantile_epsilon=quantile_epsilon,\n",
    "                                        track_coefs=True\n",
    "                                    )\n",
    "                                    anomaly_scores = model.detect()\n",
    "                                    # FROM PAPER: \n",
    "                                    # We empirically determined the setting B = 3.5 for the NAB data and B = 1 for the A3 data\n",
    "                                    threshold = 1\n",
    "                                    if 'NAB' in dataset:\n",
    "                                        threshold =  3.5\n",
    "                                    y_pred_noe = [1 if x > threshold else 0 for x in anomaly_scores[-window.shape[0]:]]\n",
    "                                    y_pred_e = apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, threshold)\n",
    "                                elif model_name == 'pci':\n",
    "                                    anomaly_scores, anomaly_labels = model.detect(data_in_memory['value'].to_numpy())\n",
    "                                    y_pred_noe = anomaly_labels[-window.shape[0]:]\n",
    "                                    # y_pred_e = apply_entropy_threshold(svd_entropies, window, boundary_bottom, boundary_up, anomaly_scores, fft_threshold)\n",
    "\n",
    "                                idx += 1\n",
    "                                y_pred_total_no_entropy += [0 if val != 1 else 1 for val in funcy.lflatten(y_pred_noe)][:window.shape[0]]\n",
    "                                y_pred_total_entropy += [0 if val != 1 else 1 for val in funcy.lflatten(y_pred_e)][:window.shape[0]]\n",
    "                                y_pred_noe = y_pred_noe[:window.shape[0]]\n",
    "                                y_pred_e = y_pred_noe[:window.shape[0]]\n",
    "\n",
    "                        except Exception as e:\n",
    "                            raise e\n",
    "\n",
    "                    # evaluate TS ########################################################################################\n",
    "\n",
    "                    # calculate batched metrics per *test_window*\n",
    "                    # for test stats we calculate F1 score for eacj class but use score for anomaly label \n",
    "                    # this works because we have binary classification\n",
    "                    data_reset = data_test.reset_index()['is_anomaly']\n",
    "                    for i in range(0, len(data_test['is_anomaly']), test_window):\n",
    "                        # here, met_total will be (precision, recall, f1_score, support)\n",
    "\n",
    "                        met_total = precision_recall_fscore_support(data_reset[i:i+test_window],\n",
    "                                                                    y_pred_total_no_entropy[:data_test.shape[0]][i:i+test_window])\n",
    "                        batch_metrices_f1_no_entropy.append(met_total[2][-1])\n",
    "\n",
    "                    score = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                                                      y_pred_total_no_entropy[:data_test.shape[0]], 0)\n",
    "                    score_entropy = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                                                      y_pred_total_entropy[:data_test.shape[0]], 0)\n",
    "\n",
    "                    # add entry to stats #######################################################################################\n",
    "\n",
    "                    try:\n",
    "                        stats_full = pd.read_csv(f'../results/scores/{model_name}_{dataset}_{training_type}_stats_entropy.csv')\n",
    "                    except:\n",
    "                        stats_full = pd.DataFrame([])\n",
    "\n",
    "                    smoothed_score = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                                                      y_pred_total_no_entropy[:data_test.shape[0]], evaluation_delay)\n",
    "                    smoothed_score_entropy = label_evaluation(data_test['is_anomaly'].tolist(), \n",
    "                                                      y_pred_total_entropy[:data_test.shape[0]], evaluation_delay)\n",
    "                    print(f'Smoothed F1 score is: {smoothed_score}')\n",
    "\n",
    "                    stats_full = stats_full.append({\n",
    "                        'model': model_name,\n",
    "                        'ts_name': filename,\n",
    "                        'window': anomaly_window,\n",
    "                        'delay': evaluation_delay,\n",
    "                        'f1_score': score,\n",
    "                        'f1_score_smoothed': smoothed_score,\n",
    "                        'f1_score_entropy': score_entropy,\n",
    "                        'f1_score_entropy_smoothed': smoothed_score_entropy,\n",
    "                        'labels_true': data_test['is_anomaly'].tolist(),\n",
    "                        'labels_pred': y_pred_total_no_entropy[:data_test.shape[0]]\n",
    "\n",
    "                    }, ignore_index=True)\n",
    "                    stats_full.to_csv(f'../results/scores/{model_name}_{dataset}_{training_type}_stats_entropy.csv', index=False)\n",
    "                    print(f'My old F1 score is: {score}')\n",
    "\n",
    "                    # plotting ##################################################################################################\n",
    "                    # general on ts\n",
    "                    if use_entropy:\n",
    "                        ts_confusion_visualization(data_test, y_pred_total_entropy, dataset, filename, model_name)\n",
    "                    else:\n",
    "                        ts_confusion_visualization(data_test, y_pred_total_no_entropy, dataset, filename, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e1a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "df10a3505701b17119fcb7e3d7f2d07794f5df50b37fdb5d4118a55945757b43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
